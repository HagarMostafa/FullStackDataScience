{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>video_id</th><th>datetime</th><th>title</th><th>transcript</th></tr><tr><td>str</td><td>datetime[μs]</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;03x2oYg9oME&quot;</td><td>2024-04-25 15:16:00</td><td>&quot;Data Science Project Managemen…</td><td>&quot;this video is part of a larger…</td></tr><tr><td>&quot;O5i_mMUM94c&quot;</td><td>2024-04-19 14:05:54</td><td>&quot;How I’d learned #datascience (…</td><td>&quot;here&#x27;s how I&#x27;d learn data scie…</td></tr><tr><td>&quot;xm9devSQEqU&quot;</td><td>2024-04-18 15:59:02</td><td>&quot;4 Skills You Need to Be a Full…</td><td>&quot;although it is common to deleg…</td></tr><tr><td>&quot;Z6CmuVEi7QY&quot;</td><td>2024-04-11 10:00:27</td><td>&quot;How I&#x27;d Learn Data Science (if…</td><td>&quot;when I was first learning data…</td></tr><tr><td>&quot;INlCLmWlojY&quot;</td><td>2024-04-04 18:45:00</td><td>&quot;I Was Wrong About AI Consultin…</td><td>&quot;last year I quit my corporate …</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────┬─────────────────────┬──────────────────────────────────┬───────────────────────────┐\n",
       "│ video_id    ┆ datetime            ┆ title                            ┆ transcript                │\n",
       "│ ---         ┆ ---                 ┆ ---                              ┆ ---                       │\n",
       "│ str         ┆ datetime[μs]        ┆ str                              ┆ str                       │\n",
       "╞═════════════╪═════════════════════╪══════════════════════════════════╪═══════════════════════════╡\n",
       "│ 03x2oYg9oME ┆ 2024-04-25 15:16:00 ┆ Data Science Project Managemen…  ┆ this video is part of a   │\n",
       "│             ┆                     ┆                                  ┆ larger…                   │\n",
       "│ O5i_mMUM94c ┆ 2024-04-19 14:05:54 ┆ How I’d learned #datascience (…  ┆ here's how I'd learn data │\n",
       "│             ┆                     ┆                                  ┆ scie…                     │\n",
       "│ xm9devSQEqU ┆ 2024-04-18 15:59:02 ┆ 4 Skills You Need to Be a Full…  ┆ although it is common to  │\n",
       "│             ┆                     ┆                                  ┆ deleg…                    │\n",
       "│ Z6CmuVEi7QY ┆ 2024-04-11 10:00:27 ┆ How I'd Learn Data Science (if…  ┆ when I was first learning │\n",
       "│             ┆                     ┆                                  ┆ data…                     │\n",
       "│ INlCLmWlojY ┆ 2024-04-04 18:45:00 ┆ I Was Wrong About AI Consultin…  ┆ last year I quit my       │\n",
       "│             ┆                     ┆                                  ┆ corporate …               │\n",
       "└─────────────┴─────────────────────┴──────────────────────────────────┴───────────────────────────┘"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet('~/Documents/Code/FullStackDataScience/Data/video-transcripts.parquet')\n",
    "df_eval = pl.read_csv('~/Documents/Code/FullStackDataScience/Data/eval-raw.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define \"parameters\"\n",
    "column_to_embed_list = ['title', 'transcript']\n",
    "model_name_list = [\"all-MiniLM-L6-v2\", \"multi-qa-distilbert-cos-v1\", \"multi-qa-mpnet-base-dot-v1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2_title\n",
      "Wall time: 989 ms\n",
      "\n",
      "all-MiniLM-L6-v2_transcript\n",
      "Wall time: 8 s\n",
      "\n",
      "multi-qa-distilbert-cos-v1_title\n",
      "Wall time: 3.32 s\n",
      "\n",
      "multi-qa-distilbert-cos-v1_transcript\n",
      "Wall time: 58.2 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_title\n",
      "Wall time: 6.67 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1_transcript\n",
      "Wall time: 1min 57s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate embeddings for each combination of column and model\n",
    "\n",
    "# initialize dict to keep track of all text embeddings\n",
    "text_embedding_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    #define embedding model\n",
    "    model = SentenceTransformer(model_name) \n",
    "\n",
    "    for column_name in column_to_embed_list:\n",
    "\n",
    "        # define text embedding identifier\n",
    "        key_name = model_name + \"_\" + column_name\n",
    "        print(key_name)\n",
    "\n",
    "        # generate embeddings for text under column_name\n",
    "        %time embedding_arr = model.encode(df[column_name].to_list())\n",
    "        print('')\n",
    "\n",
    "        # append embeddings to dict\n",
    "        text_embedding_dict[key_name] = embedding_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all-MiniLM-L6-v2\n",
      "Wall time: 929 ms\n",
      "\n",
      "multi-qa-distilbert-cos-v1\n",
      "Wall time: 3.29 s\n",
      "\n",
      "multi-qa-mpnet-base-dot-v1\n",
      "Wall time: 6 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_embedding_dict = {}\n",
    "\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    #define embedding model\n",
    "    model = SentenceTransformer(model_name)\n",
    "    print(model_name)\n",
    "\n",
    "    # embed query text\n",
    "    %time embedding_arr = model.encode(df_eval['query'].to_list())\n",
    "    print('')\n",
    "\n",
    "    # append embedding to dict\n",
    "    query_embedding_dict[model_name] = embedding_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnVideoID_index(df: pl.dataframe.frame.DataFrame, df_eval: pl.dataframe.frame.DataFrame, query_n: int) -> int:\n",
    "    \"\"\"\n",
    "        Function to return the index of a dataframe corresponding to the nth row in evaluation dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    return [i for i in range(len(df)) if df['video_id'][i]==df_eval['video_id'][query_n]][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalTrueRankings(dist_arr_isorted: np.ndarray, df: pl.dataframe.frame.DataFrame, df_eval: pl.dataframe.frame.DataFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Function to return \"true\" video ID rankings for each evaluation query\n",
    "    \"\"\"\n",
    "    \n",
    "    # intialize array to store rankings of \"correct\" search result\n",
    "    true_rank_arr = np.empty((1, dist_arr_isorted.shape[1]))\n",
    "    \n",
    "    # evaluate ranking of correct result for each query\n",
    "    for query_n in range(dist_arr_isorted.shape[1]):\n",
    "    \n",
    "        # return \"true\" video ID's in df\n",
    "        video_id_idx = returnVideoID_index(df, df_eval, query_n)\n",
    "        \n",
    "        # evaluate the ranking of the \"true\" video ID\n",
    "        true_rank = np.argwhere(dist_arr_isorted[:,query_n]==video_id_idx)[0][0]\n",
    "        \n",
    "        # store the \"true\" video ID's ranking in array\n",
    "        true_rank_arr[0,query_n] = true_rank\n",
    "\n",
    "    return true_rank_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize distance metrics to experiment\n",
    "dist_name_list = ['euclidean', 'manhattan', 'chebyshev']\n",
    "sim_name_list = ['cos_sim', 'dot_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate all possible combinations of model, columns to embed, and distance metrics\n",
    "\n",
    "# initialize list to store results\n",
    "eval_results = []\n",
    "\n",
    "# loop through all models\n",
    "for model_name in model_name_list:\n",
    "\n",
    "    # generate query embedding\n",
    "    query_embedding = query_embedding_dict[model_name]\n",
    "    \n",
    "    # loop through text columns\n",
    "    for column_name in column_to_embed_list:\n",
    "\n",
    "        # generate column embedding\n",
    "        embedding_arr = text_embedding_dict[model_name+'_'+column_name]\n",
    "\n",
    "        # loop through distance metrics\n",
    "        for dist_name in dist_name_list:\n",
    "\n",
    "            # compute distance between video text and query\n",
    "            dist = DistanceMetric.get_metric(dist_name)\n",
    "            dist_arr = dist.pairwise(embedding_arr, query_embedding)\n",
    "\n",
    "            # sort indexes of distance array\n",
    "            dist_arr_isorted = np.argsort(dist_arr, axis=0)\n",
    "\n",
    "            # define label for search method\n",
    "            method_name = \"_\".join([model_name, column_name, dist_name])\n",
    "\n",
    "            # evaluate the ranking of the ground truth\n",
    "            true_rank_arr = evalTrueRankings(dist_arr_isorted, df, df_eval)\n",
    "\n",
    "            # store results\n",
    "            eval_list = [method_name] + true_rank_arr.tolist()[0]\n",
    "            eval_results.append(eval_list)\n",
    "\n",
    "        # loop through sbert similarity scores\n",
    "        for sim_name in sim_name_list:\n",
    "            # apply similarity score from sbert\n",
    "            cmd = \"dist_arr = -util.\" + sim_name + \"(embedding_arr, query_embedding)\"\n",
    "            exec(cmd)\n",
    "    \n",
    "            # sort indexes of distance array (notice minus sign in front of cosine similarity)\n",
    "            dist_arr_isorted = np.argsort(dist_arr, axis=0)\n",
    "    \n",
    "            # define label for search method\n",
    "            method_name = \"_\".join([model_name, column_name, sim_name.replace(\"_\",\"-\")])\n",
    "    \n",
    "            # evaluate the ranking of the ground truth\n",
    "            true_rank_arr = evalTrueRankings(dist_arr_isorted, df, df_eval)\n",
    "    \n",
    "            # store results\n",
    "            eval_list = [method_name] + true_rank_arr.tolist()[0]\n",
    "            eval_results.append(eval_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
